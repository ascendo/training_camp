{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering analysis and PCA #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Please make sure that you are using the bash kernel to run this notebook.###\n",
    "### IMPORTANT: Run the command below to git pull and make sure you are running the latest code!! ###\n",
    "#### (Do this at the beginning of every session) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No local changes to save\r\n",
      "Already up-to-date.\r\n"
     ]
    }
   ],
   "source": [
    "cd /srv/scratch/training_camp/tc2017/`whoami`/src/training_camp\n",
    "git stash \n",
    "git pull "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "### Set up variables storing the location of our data\n",
    "### The proper way to load your variables is with the ~/.bashrc command, but this is very slow in iPython \n",
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/tc2017/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "export FASTQ_DIR=\"${DATA_DIR}/fastq/\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src/training_camp/src/\"\n",
    "\n",
    "export ANALYSIS_DIR=\"${WORK_DIR}/analysis/\"\n",
    "export TRIMMED_DIR=\"$ANALYSIS_DIR/trimmed\"\n",
    "export ALIGNMENT_DIR=\"$ANALYSIS_DIR/aligned/\"\n",
    "export TAGALIGN_DIR=\"$ANALYSIS_DIR/tagAlign/\"\n",
    "export PEAKS_DIR=\"$ANALYSIS_DIR/peaks/\"\n",
    "export SIGNAL_DIR=\"${ANALYSIS_DIR}signal/\"\n",
    "export FOLDCHANGE_DIR=\"${SIGNAL_DIR}foldChange/\"\n",
    "export COUNTS_DIR=\"${SIGNAL_DIR}counts/\"\n",
    "\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3/seq\"\n",
    "export YEAST_INDEX=\"/srv/scratch/training_camp/saccer3/bowtie2_index/saccer3\"\n",
    "export YEAST_CHR=\"/srv/scratch/training_camp/saccer3/sacCer3.chrom.sizes\"\n",
    "\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP \n",
    "export TMPDIR=$TMP\n",
    "\n",
    "export RLIBS=$RLIBS:\"/usr/local/lib/R/site-library\"\n",
    "\n",
    "export MASTER_DATA=\"/srv/scratch/training_camp/data/tc2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on the clustering and PCA analysis steps of the pipeline: \n",
    "![Analysis pipeline](part3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing R packages##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the scripts in this section, if you get an error saying the gplots package has not been installed, you can install the package locally by  running the **3.5 Install R packages** notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The process_peaks.sh script ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis is a simple way to visualize patterns in the data. By clustering peaks according to their signal across different time points, we may find groups of peaks that have similar behavior across these time points. By clustering samples according to their signal across peaks, we can perform a simple sanity check of data quality ‚Äê samples of the same time point should cluster together.\n",
    "\n",
    "We have developed a script to perform all the following steps. NOTE: You will see data for all 20 samples on the heatmap, not just the one sample that you analyzed. In the preprocess_peaks.sh script, we point the code to analyze the fold change & counts file for all the data that we generated prior to the tutorial -- that way you can examine all the data without having to wait for all your samples to finish aligning! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "${SRC_DIR}/process_peaks.sh\n",
    "display < ${SIGNAL_DIR}/counts_cluster.png \n",
    "display < ${SIGNAL_DIR}/foldChange_cluster.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap generation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the last step in the script above is to generate heatmaps. This step may fail if X11 is not installed. One solution is to copy the foldChange.tab file to your local computer, and then run:\n",
    "\n",
    "**[path/to/]visualize_clusters.R foldChange.tab foldChange.png**\n",
    "\n",
    "Note that visualize_clusters.R is obtained from the github repository of scripts: https://github.com/kundajelab/training_camp/blob/master/src/visualize_clusters.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a way to identify the primary directions of variation in the data. It can also be used for very coarse-grained clustering of samples; similar samples will have similar coordinates along the principal axes.\n",
    "\n",
    "We will perform PCA on foldChange.tab. The first step is to clean up the column labels in foldChange.tab with the following perl one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $SIGNAL_DIR\n",
    "perl -i\".bak\" -pe '$_ = $.==1 ? do {$_ =~ s/\\/[^\\s]+\\///g; $_ =~ s/\\\"//g; $_ =~ s/\\-/\\./g; $_ =~ s/PooledReps_Sample/samp/g; $_} : $_' $MASTER_DATA/foldChange.tab\n",
    "sed -i 's/\\_R1.trimmed.nodup\\_FE//g' $MASTER_DATA/foldChange.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now do PCA. We treat each sample as a single point in a very high dimensional space (where the dimensionality is equal to the number of genes the vary), and then we will perform dimensionality reduction in this space. We can color-code the PCA plots by \"Strain\", \"Media\", \"Salt\", or \"Rep\" to determine which parameter separates the samples most effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $SIGNAL_DIR\n",
    "#color-code by Strain \n",
    "$SRC_DIR/doPCA.R $MASTER_DATA/foldChange.tab $MASTER_DATA/batches.txt Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display the resulting PCA images\n",
    "display < PCA_scree_plot.png\n",
    "display < PC_1_vs_2.png \n",
    "display < PC_2_vs_3.png \n",
    "display < PC_1_vs_3.png\n",
    "display < PC_3_vs_4.png "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strain does not appear to be the main separator for the samples. What about media? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "$SRC_DIR/doPCA.R $MASTER_DATA/foldChange.tab $MASTER_DATA/batches.txt Media\n",
    "#display the resulting PCA images\n",
    "display < PCA_scree_plot.png\n",
    "display < PC_1_vs_2.png \n",
    "display < PC_2_vs_3.png \n",
    "display < PC_1_vs_3.png\n",
    "display < PC_3_vs_4.png "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Repeat the above analysis for \"Salt\" and \"Rep\" variables. What PC is explained by Media? What PC is explained by Salt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -n20  pc1_rotation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head -n20 pc2_rotation.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "head -n20 pc3_rotation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will produce PCA_sdev.png, which shows the standard deviation explained by each of the principle components. Since there are only 32 datapoints, the effective dimensionality of our data is 32, even though there are thousands of genes; this is why there are only 32 PCs.\n",
    "\n",
    "It also produces PC_[x]_vs_[y].png for components 1..3. How do you interpret the different principle components?\n",
    "\n",
    "Finally, it produces the files pc[x]_rotation.txt for components 1..3, which show the contribution of each peak to the direction of the principle component; this file can be used to get a sense of which peaks are critical in defining the principle components, and in which direction (positive or negative). One interesting analysis we can do with these files is to sort the peaks by their contribution to the principle component in ascending or descending order, map the peaks to their nearest genes, and then used the ranked list with software such as GOrilla which accept a ranked list of genes and output which GO terms are overrepresented towards the top: (http://cbl-gorilla.cs.technion.ac.il/)\n",
    "\n",
    "First, identify genes that are nearest to the peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $PEAKS_DIR\n",
    "bedtools closest -D a -a $MASTER_DATA/all_merged.peaks.bed.gz -b $SRC_DIR/yeast_tss_coords.bed > peaks2genes.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands will sort the genes by their contribution to each principle component and then map them to their nearest gene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd $SIGNAL_DIR\n",
    "for pcFile in `ls pc*_rotation.txt`; do\n",
    "    theBase=`basename ${pcFile}`\n",
    "    cat $pcFile | sort -k 2r > \"ascending_\"$theBase\n",
    "    cat $pcFile | sort -k 2rg > \"descending_\"$theBase\n",
    "done\n",
    "$SRC_DIR/mapToNearestPeak.py --sigPeakInputFiles ascending*.txt descending*.txt --peaks2genesFile $PEAKS_DIR/peaks2genes.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls nearestGene* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **head** command to print a specified number of lines from a file.\n",
    "Use the **cat** command to print the full contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#example: print first 20 lines in nearestGenes_ascending_pc1_rotation.txt\n",
    "head -n20 nearestGenes_ascending_pc1_rotation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: copy & paste the lists of genes into GOrilla (http://cbl-gorilla.cs.technion.ac.il/) to discover over-represented GO terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we create a symbolic link to the gene file, so that you can load it directly into GOrilla. \n",
    "ln -s $SIGNAL_DIR/nearestGenes_ascending_pc1_rotation.txt ~/training_camp/workflow_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls ~/training_camp/workflow_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
